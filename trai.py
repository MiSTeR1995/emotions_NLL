import logging
import torch
import random
import os
import datetime
from torch.utils.data import DataLoader

from utils.logger_setup import setup_logger
from utils.config_loader import ConfigLoader
from data_loading.dataset_multimodal import DatasetMultiModal
from data_loading.feature_extractor import AudioEmbeddingExtractor, TextEmbeddingExtractor

def custom_collate_fn(batch):
    """–°–æ–±–∏—Ä–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –æ–±—Ä–∞–∑—Ü–æ–≤ –≤ –µ–¥–∏–Ω—ã–π –±–∞—Ç—á, –æ—Ç–±—Ä–∞—Å—ã–≤–∞—è None."""
    batch = [x for x in batch if x is not None]
    if not batch:
        return None

    audios = [b["audio"] for b in batch]
    audio_tensor = torch.stack(audios)

    labels = [b["label"] for b in batch]
    label_tensor = torch.stack(labels)

    texts = [b["text"] for b in batch]

    return {
        "audio": audio_tensor,
        "label": label_tensor,
        "text": texts
    }

def make_dataset_and_loader(config, split: str):
    """
    –§—É–Ω–∫—Ü–∏—è, –∫–æ—Ç–æ—Ä–∞—è —Å–æ–∑–¥–∞—ë—Ç Dataset –∏ DataLoader –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ —Å–ø–ª–∏—Ç–∞.
    –ß–∏—Ç–∞–µ—Ç config.csv_path / config.wav_dir –∫–∞–∫ —à–∞–±–ª–æ–Ω—ã, –ø–æ–¥—Å—Ç–∞–≤–ª—è–µ—Ç split.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (dataset, dataloader).
    """
    print(split)
    # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—É—Ç–∏, –ø–æ–¥—Å—Ç–∞–≤–ª—è—è {split} –∏ {base_dir}
    csv_path = config.csv_path.format(base_dir=config.base_dir, split=split)
    wav_dir  = config.wav_dir.format(base_dir=config.base_dir,  split=split)

    print(csv_path)
    # –°–æ–∑–¥–∞—ë–º –¥–∞—Ç–∞—Å–µ—Ç
    dataset = DatasetMultiModal(
        csv_path           = csv_path,
        wav_dir            = wav_dir,
        emotion_columns    = config.emotion_columns,
        split              = split,
        sample_rate        = config.sample_rate,
        wav_length         = config.wav_length,
        whisper_model      = config.whisper_model,
        text_column        = config.text_column,
        use_whisper_for_nontrain_if_no_text = config.use_whisper_for_nontrain_if_no_text,
        whisper_device     = config.whisper_device,
        subset_size        = config.subset_size,
        merge_probability  = config.merge_probability
    )

    # –°–æ–∑–¥–∞—ë–º DataLoader
    dataloader = DataLoader(
        dataset,
        batch_size = config.batch_size,
        shuffle    = config.shuffle,
        num_workers= config.num_workers,
        collate_fn = custom_collate_fn
    )

    return dataset, dataloader

def main():
    os.makedirs("logs", exist_ok=True)
    datestr  = datetime.datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    log_file = os.path.join("logs", f"train_log_{datestr}.txt")
    setup_logger(logging.DEBUG, log_file=log_file)

    logging.info("üöÄ === –ó–∞–ø—É—Å–∫ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ —Å–æ –≤—Å–µ–º–∏ —Å–ø–ª–∏—Ç–∞–º–∏ ===")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥ (–±–µ–∑ –ø–æ–ª—è split)
    config = ConfigLoader("config.toml")
    config.show_config()   # –ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–µ—á–∞—Ç–∞–µ—Ç –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–æ–ª—è

    # –§–∏–∫—Å–∏—Ä—É–µ–º seed, –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω
    if config.random_seed > 0:
        random.seed(config.random_seed)
        torch.manual_seed(config.random_seed)
        logging.info(f"üîí –§–∏–∫—Å–∏—Ä—É–µ–º random seed: {config.random_seed}")
    else:
        logging.info("üîì Random seed –Ω–µ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω (0).")

    # –°–æ–∑–¥–∞—ë–º —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä—ã —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –û–î–ò–ù —Ä–∞–∑ ‚Äî –º–æ–∂–Ω–æ –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å
    audio_extractor = AudioEmbeddingExtractor(config)
    text_extractor  = TextEmbeddingExtractor(config)

    # –ü—Ä–æ–π–¥—ë–º—Å—è –ø–æ —Å–ø–∏—Å–∫—É —Å–ø–ª–∏—Ç–æ–≤
    for split_name in ["train", "dev", "test"]:
        logging.info(f"\n=== –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º split='{split_name}' ===")

        # –°–æ–∑–¥–∞—ë–º –¥–∞—Ç–∞—Å–µ—Ç –∏ DataLoader –¥–ª—è —ç—Ç–æ–≥–æ —Å–ø–ª–∏—Ç–∞
        dataset, dataloader = make_dataset_and_loader(config, split_name)

        # –î–æ–ø—É—Å—Ç–∏–º, —Ö–æ—Ç–∏–º –ø—Ä–æ—Å—Ç–æ 1 —ç–ø–æ—Ö—É –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞ (–∏–ª–∏ 2)
        for epoch in range(1):
            logging.info(f"--- –≠–ø–æ—Ö–∞ {epoch}, split={split_name} ---")

            for i, batch in enumerate(dataloader):
                if batch is None:
                    continue

                audio = batch["audio"]   # (B, 1, samples)
                labels= batch["label"]   # (B, num_emotions)
                texts = batch["text"]    # —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫

                logging.info(f"[Epoch={epoch}, split={split_name}, Batch={i}] audio={audio.shape}, labels={labels.shape}")

                # –ò–∑–≤–ª–µ–∫–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
                audio_emb = audio_extractor.extract(audio, sample_rate=config.sample_rate)
                text_emb  = text_extractor.extract(texts)

                logging.info(f"Audio emb shape: {audio_emb.shape}")
                logging.info(f"Text  emb shape: {text_emb.shape}")

                # –ó–¥–µ—Å—å –≤–∞—à–∞ –ª–æ–≥–∏–∫–∞ –æ–±—É—á–µ–Ω–∏—è / –≤–∞–ª–∏–¥–∞—Ü–∏–∏ / —Ç–µ—Å—Ç–∞
                # if split_name=='train':
                #     optimizer.zero_grad()
                #     loss=...
                #     loss.backward()
                #     optimizer.step()
                # elif split_name=='dev':
                #     ...
                # elif split_name=='test':
                #     ...

                if i==0:
                    logging.info(f"   –ü—Ä–∏–º–µ—Ä —Ç–µ–∫—Å—Ç–∞[0]: {texts[0]}")
                    logging.info(f"   –ü—Ä–∏–º–µ—Ä Audio Emb[0]: {audio_emb[0][:5]}")
                    logging.info(f"   –ü—Ä–∏–º–µ—Ä Text  Emb[0]:  {text_emb[0][:5]}")

    logging.info("‚úÖ –ì–æ—Ç–æ–≤–æ! –û–±—Ä–∞–±–æ—Ç–∫–∞ train/dev/test –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")

if __name__ == "__main__":
    main()
