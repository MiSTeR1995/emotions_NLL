import torchaudio
import torch
import os
import whisper
import unicodedata

class AudioProcessor:
    """–ö–ª–∞—Å—Å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏, –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞."""

    def __init__(self, sample_rate=16000, wav_length=2, text_source="whisper", text_column="text",
                 model="base", save_processed_audio=False, output_dir="output_wavs"):
        """
        :param sample_rate: –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏ (–ì—Ü).
        :param wav_length: –î–ª–∏–Ω–∞ –∞—É–¥–∏–æ (–≤ —Å–µ–∫—É–Ω–¥–∞—Ö).
        :param text_source: –°–ø–æ—Å–æ–± –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ ("whisper" –∏–ª–∏ "csv").
        :param text_column: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ —Å —Ç–µ–∫—Å—Ç–æ–º (–µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è "csv").
        :param model: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ Whisper ("tiny", "base", "small", "medium", "large").
        :param save_processed_audio: –°–æ—Ö—Ä–∞–Ω—è—Ç—å –ª–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –∞—É–¥–∏–æ (–∏–∑ config).
        :param output_dir: –ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∞—É–¥–∏–æ.
        """
        self.sample_rate = sample_rate
        self.wav_length = wav_length * sample_rate  # –ü–µ—Ä–µ–≤–æ–¥–∏–º —Å–µ–∫—É–Ω–¥—ã –≤ —Å—ç–º–ø–ª—ã
        self.text_source = text_source
        self.text_column = text_column
        self.model_name = model  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏

        self.save_processed_audio = save_processed_audio
        self.output_dir = output_dir

        # –ó–∞–≥—Ä—É–∂–∞–µ–º Whisper, –µ—Å–ª–∏ –≤—ã–±—Ä–∞–Ω–æ "whisper"
        self.whisper_model = whisper.load_model(self.model_name) if text_source == "whisper" else None

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∞—É–¥–∏–æ–±—ç–∫–µ–Ω–¥—ã
        available_backends = torchaudio.list_audio_backends()
        self.audio_backend = "sox_io" if "sox_io" in available_backends else "soundfile" if "soundfile" in available_backends else None

        if not self.audio_backend:
            print("‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ: –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∞—É–¥–∏–æ–±—ç–∫–µ–Ω–¥–æ–≤. torchaudio.load() –º–æ–∂–µ—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞—Ç—å.")

    def load_audio(self, path):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∞—É–¥–∏–æ—Ñ–∞–π–ª, –æ–±—Ä–µ–∑–∞–µ—Ç –µ–≥–æ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ output_dir (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)."""
        if not os.path.exists(path):
            print(f"‚ö†Ô∏è –§–∞–π–ª –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç: {path}")
            return None

        if not path.endswith(".wav"):
            print(f"‚ö†Ô∏è –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç: {path}")
            return None

        if not self.audio_backend:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞: –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ–≥–æ –∞—É–¥–∏–æ–±—ç–∫–µ–Ω–¥–∞ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ {path}")
            return None

        try:
            waveform, sample_rate = torchaudio.load(path, backend=self.audio_backend)
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {path}: {e}")
            return None

        # –í—ã–≤–æ–¥–∏–º –∏—Å—Ö–æ–¥–Ω—É—é –¥–ª–∏–Ω—É –∞—É–¥–∏–æ
        original_length = waveform.shape[1]
        print(f"üîπ –ò—Å—Ö–æ–¥–Ω–∞—è –¥–ª–∏–Ω–∞ –∞—É–¥–∏–æ: {original_length / sample_rate:.2f} —Å–µ–∫ ({original_length} —Å—ç–º–ø–ª–æ–≤)")

        # –û–±—Ä–µ–∑–∞–µ–º –∏–ª–∏ –ø–∞–¥–¥–∏–º –∞—É–¥–∏–æ –¥–æ –Ω—É–∂–Ω–æ–π –¥–ª–∏–Ω—ã
        if waveform.shape[1] < self.wav_length:
            pad_size = self.wav_length - waveform.shape[1]
            waveform = torch.nn.functional.pad(waveform, (0, pad_size))
        else:
            waveform = waveform[:, :self.wav_length]

        # –í—ã–≤–æ–¥–∏–º –Ω–æ–≤—É—é –¥–ª–∏–Ω—É –∞—É–¥–∏–æ
        processed_length = waveform.shape[1]
        print(f"‚úÖ –û–±—Ä–µ–∑–∞–Ω–Ω–æ–µ –∞—É–¥–∏–æ: {processed_length / sample_rate:.2f} —Å–µ–∫ ({processed_length} —Å—ç–º–ø–ª–æ–≤)")

        # üîπ –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –∞—É–¥–∏–æ, –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ –≤ –∫–æ–Ω—Ñ–∏–≥–µ
        if self.save_processed_audio:
            os.makedirs(self.output_dir, exist_ok=True)  # –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
            output_path = os.path.join(self.output_dir, os.path.basename(path))
            torchaudio.save(output_path, waveform, sample_rate)
            print(f"üìÅ –ê—É–¥–∏–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {output_path}")

        return waveform

    def get_text(self, path, row):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ CSV –∏–ª–∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Å Whisper."""
        if self.text_source == "csv":
            return row[self.text_column] if self.text_column in row else ""
        elif self.text_source == "whisper":
            return self.transcribe_audio(path)
        return ""

    def transcribe_audio(self, path):
        """–†–∞—Å–ø–æ–∑–Ω–∞—ë—Ç —Ç–µ–∫—Å—Ç –∏–∑ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞ —Å Whisper –∏ –æ—á–∏—â–∞–µ—Ç –µ–≥–æ."""
        if not self.whisper_model:
            return ""

        if not os.path.exists(path):
            print(f"‚ö†Ô∏è –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {path}")
            return ""

        try:
            result = self.whisper_model.transcribe(path)
            text = result["text"]
            return self.clean_text(text)  # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç –ø–µ—Ä–µ–¥ –≤–æ–∑–≤—Ä–∞—Ç–æ–º

        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ `{path}`: {e}")
            return ""

    @staticmethod
    def clean_text(text):
        """–û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –æ—Ç –Ω–µ–ø–µ—á–∞—Ç–∞–µ–º—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —é–Ω–∏–∫–æ–¥."""
        text = unicodedata.normalize("NFKC", text)  # –ü—Ä–∏–≤–æ–¥–∏–º –∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º—É —é–Ω–∏–∫–æ–¥—É
        text = text.encode("ascii", "ignore").decode("utf-8")  # –£–±–∏—Ä–∞–µ–º –≤—Å–µ –Ω–µ-ASCII —Å–∏–º–≤–æ–ª—ã
        return text.strip()
