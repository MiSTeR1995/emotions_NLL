import torch
from torch.utils.data import DataLoader
from data_loading.dataset_multimodal import DatasetMultiModal
from processing.audio_processing import AudioProcessor
from utils.config_loader import config

def custom_collate_fn(batch):
    """–£–¥–∞–ª—è–µ—Ç `None` –∏–∑ –±–∞—Ç—á–∞ –∏ –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç –ø—É—Å—Ç—ã–µ –±–∞—Ç—á–∏."""
    batch = [b for b in batch if b is not None]

    if batch:
        # –¢–µ–ø–µ—Ä—å b['audio'] –±—É–¥–µ—Ç —Ç–µ–Ω–∑–æ—Ä–æ–º, –∞ –Ω–µ –∫–æ—Ä—Ç–µ–∂–µ–º
        audio_batch = torch.stack([b['audio'] for b in batch])
        batch_dict = {
            "audio": audio_batch,
            "text": [b['text'] for b in batch],
            "label": torch.stack([b['label'] for b in batch])
        }
        return batch_dict

    return None



if __name__ == "__main__":
    print("üöÄ –ó–∞–ø—É—Å–∫ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π:")
    config.show_config()

    # üîπ –°–æ–∑–¥–∞—ë–º –¥–∞—Ç–∞—Å–µ—Ç (–±–µ–∑ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞, —á—Ç–æ–±—ã —Å–Ω–∞—á–∞–ª–∞ —Å–æ–∑–¥–∞—Ç—å `audio_class_map`, —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ split == "train")
    dataset = DatasetMultiModal(
        csv_path=config.csv_path,
        wav_dir=config.wav_dir,
        emotion_columns=config.emotion_columns,
        split=config.split,
        modalities=config.modalities,
        text_source=config.text_source,
        text_column=config.text_column
    )

    # üîπ –ï—Å–ª–∏ `train`, —Å–æ–∑–¥–∞—ë–º –∞—É–¥–∏–æ-–ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä —Å `audio_class_map`
    audio_processor = AudioProcessor(
        sample_rate=config.sample_rate,
        wav_length=config.wav_length,
        save_processed_audio=config.save_processed_audio,
        output_dir=config.audio_output_dir,
        split=config.split,
        audio_class_map=dataset.audio_class_map,
        whisper_model=config.whisper_model,
        max_text_tokens=config.max_text_tokens  # <-- –ù–æ–≤–æ–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª—è —Ç–µ–∫—Å—Ç–∞
    )

    # üîπ –ü–µ—Ä–µ–¥–∞—ë–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –≤ –¥–∞—Ç–∞—Å–µ—Ç
    dataset.audio_processor = audio_processor

    # üîπ –°–æ–∑–¥–∞—ë–º DataLoader
    dataloader = DataLoader(
        dataset,
        batch_size=config.batch_size,
        shuffle=config.shuffle,
        num_workers=config.num_workers,
        collate_fn=custom_collate_fn
    )

    print("\nüöÄ –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –¥–∞–Ω–Ω—ã—Ö –∏–∑ DataLoader...")

    for batch in dataloader:
        if batch is None:
            print("‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω –ø—É—Å—Ç–æ–π –±–∞—Ç—á")
            continue

        print(f"\nüîπ Batch –∑–∞–≥—Ä—É–∂–µ–Ω:")
        print(f"   - Batch Audio shape: {batch['audio'].shape if batch['audio'] is not None else 'None'}")
        print(f"   - Batch Emotion vector shape: {batch['label'].shape}")

        # üîπ –í—ã–≤–æ–¥–∏–º one-hot —ç–º–æ—Ü–∏–∏
        for i, emotions in enumerate(batch['label']):
            print(f"üé≠ –≠–º–æ—Ü–∏—è –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞ {i}: {emotions.tolist()}")

        # üîπ –í—ã–≤–æ–¥–∏–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
        for i, text in enumerate(batch['text']):
            text_display = text if text.strip() else "‚ö†Ô∏è [–ü—É—Å—Ç–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è]"
            print(f"üìù –¢–µ–∫—Å—Ç –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞ {i}: {text_display}")

        break  # –¢–æ–ª—å–∫–æ –æ–¥–∏–Ω –±–∞—Ç—á –¥–ª—è —Ç–µ—Å—Ç–∞
