# train.py

import logging
import torch
import random
import os
import datetime
from torch.utils.data import DataLoader

from utils.logger_setup import setup_logger
from utils.config_loader import ConfigLoader
from data_loading.dataset_multimodal import DatasetMultiModal

def custom_collate_fn(batch):
    """
    –°–æ–±–∏—Ä–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –æ–±—Ä–∞–∑—Ü–æ–≤ –≤ –µ–¥–∏–Ω—ã–π –±–∞—Ç—á, –æ—Ç–±—Ä–∞—Å—ã–≤–∞—è None.
    """
    batch = [x for x in batch if x is not None]
    if not batch:
        return None

    audios = [b["audio"] for b in batch]
    audio_tensor = torch.stack(audios)

    labels = [b["label"] for b in batch]
    label_tensor = torch.stack(labels)

    texts = [b["text"] for b in batch]

    return {
        "audio": audio_tensor,
        "label": label_tensor,
        "text": texts
    }

def main():
    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è –ª–æ–≥–æ–≤ –∏ —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞ —Å –¥–∞—Ç–æ–π/–≤—Ä–µ–º–µ–Ω–µ–º
    os.makedirs("logs", exist_ok=True)
    datestr = datetime.datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    log_file = os.path.join("logs", f"train_log_{datestr}.txt")
    setup_logger(logging.DEBUG, log_file=log_file)

    logging.info("üöÄ === –ó–∞–ø—É—Å–∫ on-the-fly —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ ===")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥
    config = ConfigLoader("config.toml")
    config.show_config()

    # –§–∏–∫—Å–∏—Ä—É–µ–º seed, –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω (seed > 0)
    if config.random_seed > 0:
        random.seed(config.random_seed)
        torch.manual_seed(config.random_seed)
        logging.info(f"üîí –§–∏–∫—Å–∏—Ä—É–µ–º random seed: {config.random_seed}")
    else:
        logging.info("üîì Random seed –Ω–µ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω (0).")

    # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç
    dataset = DatasetMultiModal(
        csv_path=config.csv_path,
        wav_dir=config.wav_dir,
        emotion_columns=config.emotion_columns,
        split=config.split,
        sample_rate=config.sample_rate,
        wav_length=config.wav_length,
        whisper_model=config.whisper_model,
        max_text_tokens=config.max_text_tokens,  # –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, –º–æ–∂–Ω–æ –æ—Å—Ç–∞–≤–∏—Ç—å –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        text_column=config.text_column,
        use_whisper_for_nontrain_if_no_text=config.use_whisper_for_nontrain_if_no_text,
        whisper_device=config.whisper_device,
        subset_size=config.subset_size
    )

    dataloader = DataLoader(
        dataset,
        batch_size=config.batch_size,
        shuffle=config.shuffle,
        num_workers=config.num_workers,
        collate_fn=custom_collate_fn
    )

    # –ü—Ä–∏–º–µ—Ä —Ü–∏–∫–ª–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ (2 —ç–ø–æ—Ö–∏)
    for epoch in range(2):
        logging.info(f"=== –≠–ø–æ—Ö–∞ {epoch} ===")
        for i, batch in enumerate(dataloader):
            if batch is None:
                continue

            audio = batch["audio"]   # (B, 1, target_samples)
            labels = batch["label"]  # (B, num_emotions)
            texts = batch["text"]    # —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫

            logging.info(f"[Epoch={epoch} Batch={i}] audio_shape={audio.shape}, label_shape={labels.shape}")
            if texts:
                logging.info(f"–ü—Ä–∏–º–µ—Ä —Ç–µ–∫—Å—Ç–∞[0]: {texts[0]}")

            # –ó–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ª–æ–≥–∏–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏

    logging.info("‚úÖ –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")

if __name__ == "__main__":
    main()
